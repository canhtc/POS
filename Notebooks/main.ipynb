{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canhtc/POS/blob/master/Notebooks/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbmSyo-V8HFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvavfzy2BwWl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR11f85WCWQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwGSV5hgCrwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.path.isfile(\"/content/drive/My Drive/Attachs/pos-train2\")\n",
        "train_data = open(\"/content/drive/My Drive/Attachs/pos-train2\").readlines()\n",
        "print(len(train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avJd2CoeDM8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = [t.split() for t in train_data]\n",
        "print(train_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pipSLK3fEOtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_sentences = []\n",
        "count_errors = 0\n",
        "for data in train_data:\n",
        "    childs = []\n",
        "    for t in data:\n",
        "        child = t.strip().split(\"/\")\n",
        "        if len(child) == 2 and child[1].isalpha():\n",
        "            childs.append(tuple([child[0],child[1].upper()]))\n",
        "        else:\n",
        "            count_errors+=1\n",
        "    if(len(childs) > 0):\n",
        "        tagged_sentences.append(childs)\n",
        "\n",
        "print(tagged_sentences[10])\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVy5JSBrFvDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(np.array(sentence))\n",
        "    sentence_tags.append(np.array(tags))\n",
        "\n",
        "print(sentences[0])\n",
        "print(sentence_tags[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB55mehDGENV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_sentences, \n",
        " test_sentences, \n",
        " train_tags, \n",
        " test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2eN9Sd3Ge1y",
        "colab_type": "text"
      },
      "source": [
        "**Keras also needs to work with numbers**\n",
        "\n",
        "(OOV – Out Of Vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqUBJvJUGWcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words, tags = set([]), set([])\n",
        "for s in train_sentences:\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        " \n",
        "for ts in train_tags:\n",
        "    for t in ts:\n",
        "        tags.add(t)\n",
        " \n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        " \n",
        "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-AzjH4zG1uT",
        "colab_type": "text"
      },
      "source": [
        "Convert the word dataset to integer dataset, both the words and the tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Yzrw_UG3UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
        " \n",
        "for s in train_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)\n",
        " \n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        " \n",
        "for s in train_tags:\n",
        "    train_tags_y.append([tag2index[t] for t in s])\n",
        " \n",
        "for s in test_tags:\n",
        "      test_tags_y.append([tag2index[t] for t in s])\n",
        "\n",
        "print(train_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_I56wcbO3A",
        "colab_type": "text"
      },
      "source": [
        "Maximum length of all the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKVDJxOVabdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
        "print(MAX_LENGTH)  # 105"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_ANDEiHbryV",
        "colab_type": "text"
      },
      "source": [
        "Keras provides an API to easily truncate and pad sequences to a common length:\n",
        "[tf.keras.preprocessing.sequence.pad_sequences](https://www.tensorflow.org/guide/keras/masking_and_padding)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvClBryhbTSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "print(train_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWUYTdSwpESr",
        "colab_type": "text"
      },
      "source": [
        "**VERSION 1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuEyvRpPcfeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "# model.add(Embedding(len(word2index), 128))\n",
        "# model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "# model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "# model.add(Activation('softmax'))\n",
        " \n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=Adam(0.001),\n",
        "#               metrics=['accuracy'])\n",
        " \n",
        "# model.summary()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpS-WLCAd6GR",
        "colab_type": "text"
      },
      "source": [
        "Transform the sequences of tags to sequences of **One-Hot Encoded tags**. This is what the Dense Layer outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsV-hYYd_Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrUOoVqgeKIV",
        "colab_type": "text"
      },
      "source": [
        "How the **one hot encoded** tags look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp95sk1MeMOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
        "print(cat_train_tags_y[0]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmETD5MydiZS",
        "colab_type": "text"
      },
      "source": [
        "***Train***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UUw8KALec3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oFGyfsveppS",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZHZ88J9esVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "# print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH5yTD-lf8F7",
        "colab_type": "text"
      },
      "source": [
        "**Test sentences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r844O9LdgVZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLCx58bVdfgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_samples = [\n",
        "    \"HN đẹp nhất về đêm\".split(),\n",
        "    \"Người đẹp nhất là người hay cười .\".split()\n",
        "]\n",
        "print(test_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v1-fmIbgMXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        " \n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUQPdBtbgUXg",
        "colab_type": "text"
      },
      "source": [
        "**First predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrRWKemqgTn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = model.predict(test_samples_X)\n",
        "# print(predictions, predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rIamLehgupz",
        "colab_type": "text"
      },
      "source": [
        "**Reverse** operation for **to_categorical**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zb_EwMyg0Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ed43lJc2g-UT",
        "colab": {}
      },
      "source": [
        "# print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlEdoBEXo789",
        "colab_type": "text"
      },
      "source": [
        "**VERSION 2:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5rP4tzShr06",
        "colab_type": "text"
      },
      "source": [
        "**Ignores the paddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHtTBdVehqQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ignore_class_accuracy(to_ignore=0):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        " \n",
        "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRdHlJTXiHhW",
        "colab_type": "text"
      },
      "source": [
        "Retrain, adding the ***ignore_class_accuracy*** metric at the compile stage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv4AjLfOiGTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy', ignore_class_accuracy(0)])\n",
        " \n",
        "model.summary()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrsP4qqxic17",
        "colab_type": "text"
      },
      "source": [
        "**Retrain:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncKS4aSgiblp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZuoIEMnp4cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   #accuracy: 97.76236414909363"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eypPJSHHiGdb",
        "colab_type": "text"
      },
      "source": [
        "**Predict again:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motDkeuqixPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_samples_X)\n",
        "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}